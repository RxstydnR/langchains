{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5d0d8a-e151-4507-96fa-91f3c1c2e617",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "- **型変換のためのOutput Parser(一部)**\n",
    "    - <font color=\"indianred\">Pydantic (JSON) parser： LLMのレスポンスをJSON（Pydanticで構築したデータモデル）に変換します</font>\n",
    "    - Structured output parser： Pydantic (JSON) parserのシンプルな版\n",
    "    - <font color=\"indianred\">BooleanOutputParser: Yes/NoをTrue/Falseに変換する</font>\n",
    "    - <font color=\"indianred\">List parser： LLMのレスポンスをList型に変換します</font>\n",
    "    - Enum parser： LLMのレスポンスをEnum型に変換します\n",
    "    - ~~Datetime parser：LLMのレスポンスをDatetime型に変換します~~\n",
    "---\n",
    "- **例外処理のためのOutput Parser**\n",
    "    - <font color=\"indianred\">Auto-fixing parser：LLMの応答を指定した型に変換できないときに別のLLMに修正依頼を出すために使います</font>\n",
    "    - ~~Retry parser：LLMの応答を指定した型に変換できないときに別のLLMにやり直させるために使います~~\n",
    " \n",
    "##### 参考\n",
    "- [【LangChainのOutput Parserとは？】Output Parserの機能と使い方を解説](https://book.st-hakky.com/data-science/langchain-outputparser/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b5a9a-8491-4f9f-8cac-32c37e38d662",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Comment\n",
    "- Yes/Noの分岐を実装するなら`BooleanOutputParser`か`Pydantic (JSON) parser`\n",
    "- 複数分岐なら`Pydantic (JSON) parser`が無難。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e36f34-f151-498e-b065-cbe53384fd00",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb96115e-cd26-45e4-ac84-1d1244eaa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6a9867f-ed2c-475c-b104-8e5c518e9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMの入出力を表示する\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7d4f972-016e-48fd-af03-9a0b7bcac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any,Callable,Dict,Iterable,List,Optional,Sized,Tuple,Union\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAI,ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# output parser\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain.output_parsers.list import CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers.pydantic import PydanticOutputParser\n",
    "from langchain.output_parsers.fix import OutputFixingParser\n",
    "from langchain.output_parsers.boolean import BooleanOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7dcc6482-d52d-48a6-b973-d788b91500ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM（モデル）を構築\n",
    "# model = OpenAI(temperature=0, model=\"gpt-3.5-turbo\", verbose=False)\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", verbose=False)\n",
    "\n",
    "# test\n",
    "# model.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195aa8d-83dd-45d5-8618-4b0128d3926c",
   "metadata": {},
   "source": [
    "## Pydantic (JSON) parser\n",
    "\n",
    "Structured output parserよりも、　設計のコード数が少なく簡単？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b40af5e5-da96-4ba3-8095-dbf1605e7575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_instructions: The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"answer\": {\"description\": \"Yes/No\", \"title\": \"Answer\", \"type\": \"boolean\"}, \"reason\": {\"description\": \"The reason why you answer yes/no.\", \"title\": \"Reason\", \"type\": \"string\"}}, \"required\": [\"answer\", \"reason\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydanticで型を定義する\n",
    "class ANSWER(BaseModel):\n",
    "    answer: bool = Field(description=\"Yes/No\")\n",
    "    reason: str  = Field(description=\"The reason why you answer yes/no.\")\n",
    "\n",
    "# OutputParserを用意する\n",
    "output_parser = PydanticOutputParser(pydantic_object=ANSWER)\n",
    "\n",
    "# フォーマットの指示を作成\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(f\"format_instructions: {format_instructions}\")\n",
    "\n",
    "# プロンプトを作成\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{text}は、正しい？ .\\n{format_instructions}\", # プロンプトテンプレート\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}, # フォーマットの指示をプロンプトに設定\n",
    "    # output_parser = ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33db319f-95a7-4c8c-9835-60d276e52afa",
   "metadata": {},
   "source": [
    "### Output Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b409c1a-584f-4459-962a-cdbfaa839090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+100/2=50.5は、正しい？ .\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"answer\": {\"description\": \"Yes/No\", \"title\": \"Answer\", \"type\": \"boolean\"}, \"reason\": {\"description\": \"The reason why you answer yes/no.\", \"title\": \"Reason\", \"type\": \"string\"}}, \"required\": [\"answer\", \"reason\"]}\\n```'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# プロンプトを作成\n",
    "prompt = prompt_template.format(text=\"1+100/2=50.5\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61549520-1417-456a-91f9-6443d5969d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": false,\n",
      "    \"reason\": \"The calculation is incorrect. The correct answer is 50.5.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# LLMに応答を出力させる\n",
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43ea760f-c82a-4964-ac99-ad63f5fa97f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANSWER(answer=False, reason='The calculation is incorrect. The correct answer is 50.5.')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 出力をパースする\n",
    "result = output_parser.parse(output.content)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d66aecf3-2869-4a3e-99a1-bfe602d900f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e1ccf-ef66-465b-b6cd-b64f51f0de5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BooleanOutputParser\n",
    "\n",
    "<font color=\"indianred\">**Note:format_instructionsはまだ未実装なので、自分で作成する必要がある。**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27ce9db6-186b-41a1-9885-13754cbc514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputParserを用意する\n",
    "output_parser = BooleanOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b103316d-ca10-47dc-b6fd-f75896dca7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_instructions: Please answer with \"yes\" or \"no.\"\n"
     ]
    }
   ],
   "source": [
    "# フォーマットの指示を作成\n",
    "format_instructions = 'Please answer with \"yes\" or \"no.\"'\n",
    "print(f\"format_instructions: {format_instructions}\")\n",
    "\n",
    "# プロンプトを作成\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{text}は、正しい？ .\\n{format_instructions}\", # プロンプトテンプレート\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}, # フォーマットの指示をプロンプトに設定\n",
    "    # output_parser = ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bc19b-98f1-4d5d-b657-06b8c2fa5563",
   "metadata": {},
   "source": [
    "### Output Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2b9c188-2df1-47f9-a94d-5a0dc9654878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+100/2=50.5は、正しい？ .\\nPlease answer with \"yes\" or \"no.\"'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# プロンプトを作成\n",
    "prompt = prompt_template.format(text=\"1+100/2=50.5\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8353c3f2-8792-4270-9d75-99a14c7f9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '1+100/2=50.5は、正しい？ .\\nPlease answer with \"yes\" or \"no.\"', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x130e44af0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x13087f5c0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1308f7ee0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 13 Apr 2024 08:18:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-sodmcyhl2pp4xdacsxhz7qnx'), (b'openai-processing-ms', b'326'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'160000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'159966'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'12ms'), (b'x-request-id', b'req_39f9febf0a1071226f3f62cd328975d9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qqH6R.q2DXFto_eic2qgwagORD4psRWMprZd5WN1wQ0-1712996328-1.0.1.1-qjKWkvlRWkPMxjOiOP2oK1MUnInPXrjzBoMy_7P6iYzWLj0SjmvhZK8SjdcKOvVp9B8BjB8PpWnV_uzVdoZ9WA; path=/; expires=Sat, 13-Apr-24 08:48:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'873a070ab94480c3-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "No.\n"
     ]
    }
   ],
   "source": [
    "# LLMに応答を出力させる\n",
    "output = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35acebdf-2447-4c42-b25d-90164facad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82f0592b-76ba-4830-9839-7deda7f3a79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(\"Yes, I do.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "53b676ce-978d-430a-8a49-839ec41434a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "BooleanOutputParser expected output value to include either YES or NO. Received Sure..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSure.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain/output_parsers/boolean.py:36\u001b[0m, in \u001b[0;36mBooleanOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBooleanOutputParser expected output value to include either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: BooleanOutputParser expected output value to include either YES or NO. Received Sure.."
     ]
    }
   ],
   "source": [
    "output_parser.parse(\"Sure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a4011347-d74e-4acc-9592-5aad7cf63eee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Ambiguous response. Both YES and NO in received: Yes/No.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYes/No\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain/output_parsers/boolean.py:27\u001b[0m, in \u001b[0;36mBooleanOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m cleaned_upper_text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m cleaned_upper_text\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_val\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m cleaned_upper_text\n\u001b[1;32m     26\u001b[0m ):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmbiguous response. Both \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfalse_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrue_val\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m cleaned_upper_text:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Ambiguous response. Both YES and NO in received: Yes/No."
     ]
    }
   ],
   "source": [
    "output_parser.parse(\"Yes/No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda792c5-e520-4dca-b3d7-4dc7b096d5ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EnumOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bbbca5e-cee0-40c6-8544-e674128a3bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format_instructions: Select one of the following options: yes, no\n"
     ]
    }
   ],
   "source": [
    "# 事前にEnumで型を定義\n",
    "from enum import Enum\n",
    "\n",
    "class ANSWER(Enum):\n",
    "    YES = \"yes\"\n",
    "    NO  = \"no\"\n",
    "\n",
    "# OutputParserを用意\n",
    "output_parser = EnumOutputParser(enum=ANSWER) # Enumオブジェクトを引数に渡す\n",
    "\n",
    "# フォーマットの指示を作成\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(f\"format_instructions: {format_instructions}\") # format_instructions: Select one of the following options: red, blue, green\n",
    "\n",
    "# プロンプトのテンプレートを作成\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{text}は、正しい？ .\\n{format_instructions}\", # プロンプトテンプレート\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions} # フォーマットの指示をプロンプトに設定\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58a127-d7eb-4f9f-8c72-03ce92e1ffb0",
   "metadata": {},
   "source": [
    "### Output Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73113914-42d8-4219-a662-e422a18f2e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1=2は、正しい？ .\\nSelect one of the following options: yes, no'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# プロンプトを作成\n",
    "prompt = prompt_template.format(text=\"1+1=2\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9f35bff-601e-4f9f-b1b8-1178e505386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "# LLMに応答を出力させる\n",
    "output = model.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb3571ed-f60d-49d8-be32-13043568473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER.YES\n"
     ]
    }
   ],
   "source": [
    "# 出力をパースする\n",
    "result = output_parser.parse(output.content)\n",
    "print(result)\n",
    "# Enum型で出力される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fe170-a947-44b3-b6ff-7d1681c1f6b7",
   "metadata": {},
   "source": [
    "## Auto-fixing parser（OutputFixingParser）\n",
    "\n",
    "Auto-fixing parser（OutputFixingParser）は、LLM（モデル）の応答を他のOutput Parserで変換しようとして例外が発生した時に、別のLLMに修正依頼を出すことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640963d-460d-4f64-ba98-3fab8e2d9d21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4f4e9d4-5d99-4ebb-a094-0be93c340e02",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: {'name': 'NameName', 'address': 'AddressAddress'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:212\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:157\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:125\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m misformatted_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNameName\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAddressAddress\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 回答をパースしようとする\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/pydantic.py:64\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TBaseModel:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:218\u001b[0m, in \u001b[0;36mJsonOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/pydantic.py:60\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_result\u001b[39m(\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m, result: List[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TBaseModel:\n\u001b[0;32m---> 60\u001b[0m     json_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_obj(json_object)\n",
      "File \u001b[0;32m~/Desktop/vector/env/lib/python3.10/site-packages/langchain_core/output_parsers/json.py:215\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    214\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Invalid json output: {'name': 'NameName', 'address': 'AddressAddress'}"
     ]
    }
   ],
   "source": [
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"人物名\")\n",
    "    address: str = Field(description=\"住所\")\n",
    "        \n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "# misformatted_outputは解析できない回答とする\n",
    "misformatted_output = \"{'name': 'NameName', 'address': 'AddressAddress'}\"\n",
    "\n",
    "# 回答をパースしようとする\n",
    "parser.parse(misformatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53458b-4dd9-4b72-9fba-f4fc75593949",
   "metadata": {},
   "source": [
    "### Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d8cefaf-3d51-405a-ad59-882f3165729e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Instructions:\\n--------------\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"\\\\u4eba\\\\u7269\\\\u540d\", \"title\": \"Name\", \"type\": \"string\"}, \"address\": {\"description\": \"\\\\u4f4f\\\\u6240\", \"title\": \"Address\", \"type\": \"string\"}}, \"required\": [\"name\", \"address\"]}\\n```\\n--------------\\nCompletion:\\n--------------\\n{\\'name\\': \\'NameName\\', \\'address\\': \\'AddressAddress\\'}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\nOutputParserException(\"Invalid json output: {\\'name\\': \\'NameName\\', \\'address\\': \\'AddressAddress\\'}\")\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:', 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x130f903a0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x13087f5c0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x130e44af0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 13 Apr 2024 08:05:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-sodmcyhl2pp4xdacsxhz7qnx'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'160000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'159699'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'112ms'), (b'x-request-id', b'req_b234a04c85aa3f6f6179bc979592c4e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8739f3feae0125f0-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "name='NameName' address='AddressAddress'\n"
     ]
    }
   ],
   "source": [
    "# OutputFixingParserでPydanticOutputParserをラップする\n",
    "output_fixing_parser = OutputFixingParser.from_llm(parser=parser,llm=model)\n",
    "\n",
    "# OutputFixingParserでパースする\n",
    "result = output_fixing_parser.parse(misformatted_output)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "471a7506-6ff2-4e15-9493-9a279151d534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions:\n",
      "--------------\n",
      "{instructions}\n",
      "--------------\n",
      "Completion:\n",
      "--------------\n",
      "{completion}\n",
      "--------------\n",
      "\n",
      "Above, the Completion did not satisfy the constraints given in the Instructions.\n",
      "Error:\n",
      "--------------\n",
      "{error}\n",
      "--------------\n",
      "\n",
      "Please try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:\n"
     ]
    }
   ],
   "source": [
    "# LLMに送られるプロンプトテンプレート\n",
    "print(output_fixing_parser.retry_chain.prompt.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
