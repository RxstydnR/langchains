{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ef724e",
   "metadata": {},
   "source": [
    "# Step-Back Prompting (Question-Answering)\n",
    "\n",
    "One prompting technique called \"Step-Back\" prompting can improve performance on complex questions by first asking a \"step back\" question. This can be combined with regular question-answering applications by then doing retrieval on both the original and step-back question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75501f46-fa26-4922-90ed-6a31be7248dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b5cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1a681a-c748-4bee-a618-0ad8c2d250f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPBACK_PROMPT_TEMPLATE=\"\"\"\n",
    "You are an expert at world knowledge.\n",
    "Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\n",
    "\n",
    "Here are a few examples:\n",
    "Question: Could the members of The Police perform lawful arrests?\n",
    "Step-back Question: what can the members of The Police do?\n",
    "\n",
    "Question: Jan Sindel’s was born in what country?\n",
    "Step-back Question: what is Jan Sindel’s personal history?\n",
    "\n",
    "Question: {question}\n",
    "Step-back Question: \n",
    "\"\"\"\n",
    "# Question -> Human Message\n",
    "# Step-back Question -> AI Message\n",
    "# の方がいいのかも？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb5ef73-e748-415f-abc2-636e8eeba65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプトを作成\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    template=STEPBACK_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70fc9b78-9180-4d4a-8eee-d752fe9ff7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert at world knowledge.\\nYour task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer.\\n\\nHere are a few examples:\\nQuestion: Could the members of The Police perform lawful arrests?\\nStep-back Question: what can the members of The Police do?\\n\\nQuestion: Jan Sindel’s was born in what country?\\nStep-back Question: what is Jan Sindel’s personal history?\\n\\nQuestion: 大谷翔平が2019年に所属していた球団はどこ？\\nStep-back Question: \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# プロンプトを作成\n",
    "prompt = prompt_template.format(question=\"大谷翔平が2019年に所属していた球団はどこ？\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca4182c8-dc1d-4d9a-ae4b-42f0a5c04ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM（モデル）を構築\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8312823f-816f-48ac-a126-f40757106cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大谷翔平はどの球団に所属していたか？'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11798e5d-f19d-43f3-8be3-5b14855e3a18",
   "metadata": {},
   "source": [
    "<font color=\"indianred\" size=\"5\">**実際にStepBack-RAGをする際は、normal_contextとstepback_contextの両方を入力する必要がある。**以下の実装を要参照。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095db806-9b33-47ae-8876-5c0a482654b8",
   "metadata": {},
   "source": [
    "### StepBack-RAGの実装例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b9396bb-762f-4c5e-a5b0-24831ce63de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66657fdd-5d7a-478c-a217-a1b0d09892c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
      "\n",
      "{normal_context}\n",
      "{step_back_context}\n",
      "\n",
      "Original Question: {question}\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(response_prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "97a6d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": question_gen | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ce554cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, ChatGPT was not around while Donald Trump was president. ChatGPT was launched on November 30, 2022, which is after Donald Trump's presidency. The context provided mentions that during the Trump administration, Altman, the CEO of OpenAI, gained attention as a vocal critic of the president. This suggests that ChatGPT was not developed or available during that time.\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
